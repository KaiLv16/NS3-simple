                      name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type        input_shape       output_shape                            param_shape kwargs dtype_size
0                        x                                     ()        0         0        0         0         0         0    placeholder                        x         None               None               None                                   None     {}       None
1                    conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d    [10, 1, 28, 28]   [10, 64, 30, 30]              {'weight': (64, 1, 3, 3)}     {}        [4]
2                      bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d   [10, 64, 30, 30]   [10, 64, 30, 30]       {'weight': (64,), 'bias': (64,)}     {}        [4]
3                     relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU   [10, 64, 30, 30]   [10, 64, 30, 30]                                     {}     {}        [4]
4                  maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d   [10, 64, 30, 30]   [10, 64, 15, 15]                                     {}     {}        [4]
5           layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 1, 1)}     {}        [4]
6             layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
7            layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
8           layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]
9             layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
10         layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
11          layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]
12            layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]
13   layer1_0_downsample_0                             (maxpool,)   144000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]
14   layer1_0_downsample_1               (layer1_0_downsample_0,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]
15                     add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]
16         layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]
17          layer1_1_conv1                     (layer1_0_relu_2,)   576000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d  [10, 256, 15, 15]   [10, 64, 15, 15]            {'weight': (64, 256, 1, 1)}     {}        [4]
18            layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
19           layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
20          layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]
21            layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
22         layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
23          layer1_1_conv3                     (layer1_1_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]
24            layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]
25                   add_1        (layer1_1_bn3, layer1_0_relu_2)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]
26         layer1_1_relu_2                               (add_1,)   576000    576000        0         0         0         0    call_module            layer1.1.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]
27          layer1_2_conv1                     (layer1_1_relu_2,)   576000    144000    16384         0         0         0    call_module           layer1.2.conv1       Conv2d  [10, 256, 15, 15]   [10, 64, 15, 15]            {'weight': (64, 256, 1, 1)}     {}        [4]
28            layer1_2_bn1                      (layer1_2_conv1,)   144000    144000      128         0         0         0    call_module             layer1.2.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
29           layer1_2_relu                        (layer1_2_bn1,)   144000    144000        0         0         0         0    call_module            layer1.2.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
30          layer1_2_conv2                       (layer1_2_relu,)   144000    144000    36864         0         0         0    call_module           layer1.2.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]
31            layer1_2_bn2                      (layer1_2_conv2,)   144000    144000      128         0         0         0    call_module             layer1.2.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]
32         layer1_2_relu_1                        (layer1_2_bn2,)   144000    144000        0         0         0         0    call_module            layer1.2.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]
33          layer1_2_conv3                     (layer1_2_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.2.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]
34            layer1_2_bn3                      (layer1_2_conv3,)   576000    576000      512         0         0         0    call_module             layer1.2.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]
35                   add_2        (layer1_2_bn3, layer1_1_relu_2)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]
36         layer1_2_relu_2                               (add_2,)   576000    576000        0         0         0         0    call_module            layer1.2.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]
37          layer2_0_conv1                     (layer1_2_relu_2,)   576000     81920    32768         0         0         0    call_module           layer2.0.conv1       Conv2d  [10, 256, 15, 15]    [10, 128, 8, 8]           {'weight': (128, 256, 1, 1)}     {}        [4]
38            layer2_0_bn1                      (layer2_0_conv1,)    81920     81920      256         0         0         0    call_module             layer2.0.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
39           layer2_0_relu                        (layer2_0_bn1,)    81920     81920        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
40          layer2_0_conv2                       (layer2_0_relu,)    81920     81920   147456         0         0         0    call_module           layer2.0.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]
41            layer2_0_bn2                      (layer2_0_conv2,)    81920     81920      256         0         0         0    call_module             layer2.0.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
42         layer2_0_relu_1                        (layer2_0_bn2,)    81920     81920        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
43          layer2_0_conv3                     (layer2_0_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.0.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]
44            layer2_0_bn3                      (layer2_0_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.0.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]
45   layer2_0_downsample_0                     (layer1_2_relu_2,)   576000    327680   131072         0         0         0    call_module    layer2.0.downsample.0       Conv2d  [10, 256, 15, 15]    [10, 512, 8, 8]           {'weight': (512, 256, 1, 1)}     {}        [4]
46   layer2_0_downsample_1               (layer2_0_downsample_0,)   327680    327680     1024         0         0         0    call_module    layer2.0.downsample.1  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]
47                   add_3  (layer2_0_bn3, layer2_0_downsample_1)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]
48         layer2_0_relu_2                               (add_3,)   327680    327680        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]
49          layer2_1_conv1                     (layer2_0_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.1.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]
50            layer2_1_bn1                      (layer2_1_conv1,)    81920     81920      256         0         0         0    call_module             layer2.1.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
51           layer2_1_relu                        (layer2_1_bn1,)    81920     81920        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
52          layer2_1_conv2                       (layer2_1_relu,)    81920     81920   147456         0         0         0    call_module           layer2.1.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]
53            layer2_1_bn2                      (layer2_1_conv2,)    81920     81920      256         0         0         0    call_module             layer2.1.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
54         layer2_1_relu_1                        (layer2_1_bn2,)    81920     81920        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
55          layer2_1_conv3                     (layer2_1_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.1.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]
56            layer2_1_bn3                      (layer2_1_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.1.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]
57                   add_4        (layer2_1_bn3, layer2_0_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]
58         layer2_1_relu_2                               (add_4,)   327680    327680        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]
59          layer2_2_conv1                     (layer2_1_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.2.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]
60            layer2_2_bn1                      (layer2_2_conv1,)    81920     81920      256         0         0         0    call_module             layer2.2.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
61           layer2_2_relu                        (layer2_2_bn1,)    81920     81920        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
62          layer2_2_conv2                       (layer2_2_relu,)    81920     81920   147456         0         0         0    call_module           layer2.2.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]
63            layer2_2_bn2                      (layer2_2_conv2,)    81920     81920      256         0         0         0    call_module             layer2.2.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
64         layer2_2_relu_1                        (layer2_2_bn2,)    81920     81920        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
65          layer2_2_conv3                     (layer2_2_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.2.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]
66            layer2_2_bn3                      (layer2_2_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.2.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]
67                   add_5        (layer2_2_bn3, layer2_1_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]
68         layer2_2_relu_2                               (add_5,)   327680    327680        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]
69          layer2_3_conv1                     (layer2_2_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.3.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]
70            layer2_3_bn1                      (layer2_3_conv1,)    81920     81920      256         0         0         0    call_module             layer2.3.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
71           layer2_3_relu                        (layer2_3_bn1,)    81920     81920        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
72          layer2_3_conv2                       (layer2_3_relu,)    81920     81920   147456         0         0         0    call_module           layer2.3.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]
73            layer2_3_bn2                      (layer2_3_conv2,)    81920     81920      256         0         0         0    call_module             layer2.3.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]
74         layer2_3_relu_1                        (layer2_3_bn2,)    81920     81920        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]
75          layer2_3_conv3                     (layer2_3_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.3.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]
76            layer2_3_bn3                      (layer2_3_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.3.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]
77                   add_6        (layer2_3_bn3, layer2_2_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]
78         layer2_3_relu_2                               (add_6,)   327680    327680        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]
79          layer3_0_conv1                     (layer2_3_relu_2,)   327680     40960   131072         0         0         0    call_module           layer3.0.conv1       Conv2d    [10, 512, 8, 8]    [10, 256, 4, 4]           {'weight': (256, 512, 1, 1)}     {}        [4]
80            layer3_0_bn1                      (layer3_0_conv1,)    40960     40960      512         0         0         0    call_module             layer3.0.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
81           layer3_0_relu                        (layer3_0_bn1,)    40960     40960        0         0         0         0    call_module            layer3.0.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
82          layer3_0_conv2                       (layer3_0_relu,)    40960     40960   589824         0         0         0    call_module           layer3.0.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
83            layer3_0_bn2                      (layer3_0_conv2,)    40960     40960      512         0         0         0    call_module             layer3.0.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
84         layer3_0_relu_1                        (layer3_0_bn2,)    40960     40960        0         0         0         0    call_module            layer3.0.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
85          layer3_0_conv3                     (layer3_0_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.0.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
86            layer3_0_bn3                      (layer3_0_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.0.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
87   layer3_0_downsample_0                     (layer2_3_relu_2,)   327680    163840   524288         0         0         0    call_module    layer3.0.downsample.0       Conv2d    [10, 512, 8, 8]   [10, 1024, 4, 4]          {'weight': (1024, 512, 1, 1)}     {}        [4]
88   layer3_0_downsample_1               (layer3_0_downsample_0,)   163840    163840     2048         0         0         0    call_module    layer3.0.downsample.1  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
89                   add_7  (layer3_0_bn3, layer3_0_downsample_1)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
90         layer3_0_relu_2                               (add_7,)   163840    163840        0         0         0         0    call_module            layer3.0.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
91          layer3_1_conv1                     (layer3_0_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.1.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]
92            layer3_1_bn1                      (layer3_1_conv1,)    40960     40960      512         0         0         0    call_module             layer3.1.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
93           layer3_1_relu                        (layer3_1_bn1,)    40960     40960        0         0         0         0    call_module            layer3.1.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
94          layer3_1_conv2                       (layer3_1_relu,)    40960     40960   589824         0         0         0    call_module           layer3.1.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
95            layer3_1_bn2                      (layer3_1_conv2,)    40960     40960      512         0         0         0    call_module             layer3.1.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
96         layer3_1_relu_1                        (layer3_1_bn2,)    40960     40960        0         0         0         0    call_module            layer3.1.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
97          layer3_1_conv3                     (layer3_1_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.1.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
98            layer3_1_bn3                      (layer3_1_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.1.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
99                   add_8        (layer3_1_bn3, layer3_0_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
100        layer3_1_relu_2                               (add_8,)   163840    163840        0         0         0         0    call_module            layer3.1.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
101         layer3_2_conv1                     (layer3_1_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.2.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]
102           layer3_2_bn1                      (layer3_2_conv1,)    40960     40960      512         0         0         0    call_module             layer3.2.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
103          layer3_2_relu                        (layer3_2_bn1,)    40960     40960        0         0         0         0    call_module            layer3.2.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
104         layer3_2_conv2                       (layer3_2_relu,)    40960     40960   589824         0         0         0    call_module           layer3.2.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
105           layer3_2_bn2                      (layer3_2_conv2,)    40960     40960      512         0         0         0    call_module             layer3.2.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
106        layer3_2_relu_1                        (layer3_2_bn2,)    40960     40960        0         0         0         0    call_module            layer3.2.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
107         layer3_2_conv3                     (layer3_2_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.2.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
108           layer3_2_bn3                      (layer3_2_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.2.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
109                  add_9        (layer3_2_bn3, layer3_1_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
110        layer3_2_relu_2                               (add_9,)   163840    163840        0         0         0         0    call_module            layer3.2.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
111         layer3_3_conv1                     (layer3_2_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.3.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]
112           layer3_3_bn1                      (layer3_3_conv1,)    40960     40960      512         0         0         0    call_module             layer3.3.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
113          layer3_3_relu                        (layer3_3_bn1,)    40960     40960        0         0         0         0    call_module            layer3.3.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
114         layer3_3_conv2                       (layer3_3_relu,)    40960     40960   589824         0         0         0    call_module           layer3.3.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
115           layer3_3_bn2                      (layer3_3_conv2,)    40960     40960      512         0         0         0    call_module             layer3.3.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
116        layer3_3_relu_1                        (layer3_3_bn2,)    40960     40960        0         0         0         0    call_module            layer3.3.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
117         layer3_3_conv3                     (layer3_3_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.3.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
118           layer3_3_bn3                      (layer3_3_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.3.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
119                 add_10        (layer3_3_bn3, layer3_2_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
120        layer3_3_relu_2                              (add_10,)   163840    163840        0         0         0         0    call_module            layer3.3.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
121         layer3_4_conv1                     (layer3_3_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.4.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]
122           layer3_4_bn1                      (layer3_4_conv1,)    40960     40960      512         0         0         0    call_module             layer3.4.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
123          layer3_4_relu                        (layer3_4_bn1,)    40960     40960        0         0         0         0    call_module            layer3.4.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
124         layer3_4_conv2                       (layer3_4_relu,)    40960     40960   589824         0         0         0    call_module           layer3.4.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
125           layer3_4_bn2                      (layer3_4_conv2,)    40960     40960      512         0         0         0    call_module             layer3.4.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
126        layer3_4_relu_1                        (layer3_4_bn2,)    40960     40960        0         0         0         0    call_module            layer3.4.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
127         layer3_4_conv3                     (layer3_4_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.4.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
128           layer3_4_bn3                      (layer3_4_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.4.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
129                 add_11        (layer3_4_bn3, layer3_3_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
130        layer3_4_relu_2                              (add_11,)   163840    163840        0         0         0         0    call_module            layer3.4.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
131         layer3_5_conv1                     (layer3_4_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.5.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]
132           layer3_5_bn1                      (layer3_5_conv1,)    40960     40960      512         0         0         0    call_module             layer3.5.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
133          layer3_5_relu                        (layer3_5_bn1,)    40960     40960        0         0         0         0    call_module            layer3.5.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
134         layer3_5_conv2                       (layer3_5_relu,)    40960     40960   589824         0         0         0    call_module           layer3.5.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]
135           layer3_5_bn2                      (layer3_5_conv2,)    40960     40960      512         0         0         0    call_module             layer3.5.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]
136        layer3_5_relu_1                        (layer3_5_bn2,)    40960     40960        0         0         0         0    call_module            layer3.5.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]
137         layer3_5_conv3                     (layer3_5_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.5.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]
138           layer3_5_bn3                      (layer3_5_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.5.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]
139                 add_12        (layer3_5_bn3, layer3_4_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]
140        layer3_5_relu_2                              (add_12,)   163840    163840        0         0         0         0    call_module            layer3.5.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]
141         layer4_0_conv1                     (layer3_5_relu_2,)   163840     20480   524288         0         0         0    call_module           layer4.0.conv1       Conv2d   [10, 1024, 4, 4]    [10, 512, 2, 2]          {'weight': (512, 1024, 1, 1)}     {}        [4]
142           layer4_0_bn1                      (layer4_0_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.0.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
143          layer4_0_relu                        (layer4_0_bn1,)    20480     20480        0         0         0         0    call_module            layer4.0.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
144         layer4_0_conv2                       (layer4_0_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.0.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]
145           layer4_0_bn2                      (layer4_0_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.0.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
146        layer4_0_relu_1                        (layer4_0_bn2,)    20480     20480        0         0         0         0    call_module            layer4.0.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
147         layer4_0_conv3                     (layer4_0_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.0.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]
148           layer4_0_bn3                      (layer4_0_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.0.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]
149  layer4_0_downsample_0                     (layer3_5_relu_2,)   163840     81920  2097152         0         0         0    call_module    layer4.0.downsample.0       Conv2d   [10, 1024, 4, 4]   [10, 2048, 2, 2]         {'weight': (2048, 1024, 1, 1)}     {}        [4]
150  layer4_0_downsample_1               (layer4_0_downsample_0,)    81920     81920     4096         0         0         0    call_module    layer4.0.downsample.1  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]
151                 add_13  (layer4_0_bn3, layer4_0_downsample_1)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]
152        layer4_0_relu_2                              (add_13,)    81920     81920        0         0         0         0    call_module            layer4.0.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]
153         layer4_1_conv1                     (layer4_0_relu_2,)    81920     20480  1048576         0         0         0    call_module           layer4.1.conv1       Conv2d   [10, 2048, 2, 2]    [10, 512, 2, 2]          {'weight': (512, 2048, 1, 1)}     {}        [4]
154           layer4_1_bn1                      (layer4_1_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.1.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
155          layer4_1_relu                        (layer4_1_bn1,)    20480     20480        0         0         0         0    call_module            layer4.1.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
156         layer4_1_conv2                       (layer4_1_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.1.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]
157           layer4_1_bn2                      (layer4_1_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.1.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
158        layer4_1_relu_1                        (layer4_1_bn2,)    20480     20480        0         0         0         0    call_module            layer4.1.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
159         layer4_1_conv3                     (layer4_1_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.1.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]
160           layer4_1_bn3                      (layer4_1_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.1.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]
161                 add_14        (layer4_1_bn3, layer4_0_relu_2)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]
162        layer4_1_relu_2                              (add_14,)    81920     81920        0         0         0         0    call_module            layer4.1.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]
163         layer4_2_conv1                     (layer4_1_relu_2,)    81920     20480  1048576         0         0         0    call_module           layer4.2.conv1       Conv2d   [10, 2048, 2, 2]    [10, 512, 2, 2]          {'weight': (512, 2048, 1, 1)}     {}        [4]
164           layer4_2_bn1                      (layer4_2_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.2.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
165          layer4_2_relu                        (layer4_2_bn1,)    20480     20480        0         0         0         0    call_module            layer4.2.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
166         layer4_2_conv2                       (layer4_2_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.2.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]
167           layer4_2_bn2                      (layer4_2_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.2.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]
168        layer4_2_relu_1                        (layer4_2_bn2,)    20480     20480        0         0         0         0    call_module            layer4.2.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]
169         layer4_2_conv3                     (layer4_2_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.2.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]
170           layer4_2_bn3                      (layer4_2_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.2.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]
171                 add_15        (layer4_2_bn3, layer4_1_relu_2)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]
172        layer4_2_relu_2                              (add_15,)    81920     81920        0         0         0         0    call_module            layer4.2.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]
173                avgpool                     (layer4_2_relu_2,)    81920     20480        0         0         0         0    call_module                  avgpool    AvgPool2d   [10, 2048, 2, 2]   [10, 2048, 1, 1]                                     {}     {}        [4]
174                   size                           (avgpool, 0)    20480     20480        0         0         0         0    call_method                     size         None   [10, 2048, 1, 1]   [10, 2048, 1, 1]                                      0     {}        [4]
175                   view                    (avgpool, size, -1)    20480     20480        0         0         0         0    call_method                     view         None   [10, 2048, 1, 1]   [10, 2048, 1, 1]                                      0     {}        [4]
176                     fc                                (view,)    20480       100    20490         0         0         0    call_module                       fc       Linear         [10, 2048]           [10, 10]  {'weight': (10, 2048), 'bias': (10,)}     {}        [4]
177                 output                                  (fc,)      100       100        0         0         0         0         output                   output         None           [10, 10]           [10, 10]                                      0     {}        [4]
                      name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type        input_shape       output_shape                            param_shape kwargs dtype_size  avg_mem_grp_idx  avg_mem_grp_size
0                        x                                     ()        0         0        0         0         0         0    placeholder                        x         None               None               None                                   None     {}       None                1           3211200
1                    conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d    [10, 1, 28, 28]   [10, 64, 30, 30]              {'weight': (64, 1, 3, 3)}     {}        [4]                1           3211200
2                      bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d   [10, 64, 30, 30]   [10, 64, 30, 30]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
3                     relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU   [10, 64, 30, 30]   [10, 64, 30, 30]                                     {}     {}        [4]                1           3211200
4                  maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d   [10, 64, 30, 30]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
5           layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 1, 1)}     {}        [4]                1           3211200
6             layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
7            layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
8           layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]                1           3211200
9             layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
10         layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
11          layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]                1           3211200
12            layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
13   layer1_0_downsample_0                             (maxpool,)   144000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]                1           3211200
14   layer1_0_downsample_1               (layer1_0_downsample_0,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
15                     add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]                1           3211200
16         layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]                1           3211200
17          layer1_1_conv1                     (layer1_0_relu_2,)   576000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d  [10, 256, 15, 15]   [10, 64, 15, 15]            {'weight': (64, 256, 1, 1)}     {}        [4]                1           3211200
18            layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
19           layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
20          layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]                1           3211200
21            layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
22         layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
23          layer1_1_conv3                     (layer1_1_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]                1           3211200
24            layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
25                   add_1        (layer1_1_bn3, layer1_0_relu_2)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]                1           3211200
26         layer1_1_relu_2                               (add_1,)   576000    576000        0         0         0         0    call_module            layer1.1.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]                1           3211200
27          layer1_2_conv1                     (layer1_1_relu_2,)   576000    144000    16384         0         0         0    call_module           layer1.2.conv1       Conv2d  [10, 256, 15, 15]   [10, 64, 15, 15]            {'weight': (64, 256, 1, 1)}     {}        [4]                1           3211200
28            layer1_2_bn1                      (layer1_2_conv1,)   144000    144000      128         0         0         0    call_module             layer1.2.bn1  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
29           layer1_2_relu                        (layer1_2_bn1,)   144000    144000        0         0         0         0    call_module            layer1.2.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
30          layer1_2_conv2                       (layer1_2_relu,)   144000    144000    36864         0         0         0    call_module           layer1.2.conv2       Conv2d   [10, 64, 15, 15]   [10, 64, 15, 15]             {'weight': (64, 64, 3, 3)}     {}        [4]                1           3211200
31            layer1_2_bn2                      (layer1_2_conv2,)   144000    144000      128         0         0         0    call_module             layer1.2.bn2  BatchNorm2d   [10, 64, 15, 15]   [10, 64, 15, 15]       {'weight': (64,), 'bias': (64,)}     {}        [4]                1           3211200
32         layer1_2_relu_1                        (layer1_2_bn2,)   144000    144000        0         0         0         0    call_module            layer1.2.relu         ReLU   [10, 64, 15, 15]   [10, 64, 15, 15]                                     {}     {}        [4]                1           3211200
33          layer1_2_conv3                     (layer1_2_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.2.conv3       Conv2d   [10, 64, 15, 15]  [10, 256, 15, 15]            {'weight': (256, 64, 1, 1)}     {}        [4]                1           3211200
34            layer1_2_bn3                      (layer1_2_conv3,)   576000    576000      512         0         0         0    call_module             layer1.2.bn3  BatchNorm2d  [10, 256, 15, 15]  [10, 256, 15, 15]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
35                   add_2        (layer1_2_bn3, layer1_1_relu_2)   576000    576000        0         0         0         0  call_function  <built-in function add>         None  [10, 256, 15, 15]  [10, 256, 15, 15]                                      0     {}        [4]                1           3211200
36         layer1_2_relu_2                               (add_2,)   576000    576000        0         0         0         0    call_module            layer1.2.relu         ReLU  [10, 256, 15, 15]  [10, 256, 15, 15]                                     {}     {}        [4]                1           3211200
37          layer2_0_conv1                     (layer1_2_relu_2,)   576000     81920    32768         0         0         0    call_module           layer2.0.conv1       Conv2d  [10, 256, 15, 15]    [10, 128, 8, 8]           {'weight': (128, 256, 1, 1)}     {}        [4]                1           3211200
38            layer2_0_bn1                      (layer2_0_conv1,)    81920     81920      256         0         0         0    call_module             layer2.0.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
39           layer2_0_relu                        (layer2_0_bn1,)    81920     81920        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
40          layer2_0_conv2                       (layer2_0_relu,)    81920     81920   147456         0         0         0    call_module           layer2.0.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]                1           3211200
41            layer2_0_bn2                      (layer2_0_conv2,)    81920     81920      256         0         0         0    call_module             layer2.0.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
42         layer2_0_relu_1                        (layer2_0_bn2,)    81920     81920        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
43          layer2_0_conv3                     (layer2_0_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.0.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]                1           3211200
44            layer2_0_bn3                      (layer2_0_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.0.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]                1           3211200
45   layer2_0_downsample_0                     (layer1_2_relu_2,)   576000    327680   131072         0         0         0    call_module    layer2.0.downsample.0       Conv2d  [10, 256, 15, 15]    [10, 512, 8, 8]           {'weight': (512, 256, 1, 1)}     {}        [4]                1           3211200
46   layer2_0_downsample_1               (layer2_0_downsample_0,)   327680    327680     1024         0         0         0    call_module    layer2.0.downsample.1  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]                1           3211200
47                   add_3  (layer2_0_bn3, layer2_0_downsample_1)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]                1           3211200
48         layer2_0_relu_2                               (add_3,)   327680    327680        0         0         0         0    call_module            layer2.0.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]                1           3211200
49          layer2_1_conv1                     (layer2_0_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.1.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]                1           3211200
50            layer2_1_bn1                      (layer2_1_conv1,)    81920     81920      256         0         0         0    call_module             layer2.1.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
51           layer2_1_relu                        (layer2_1_bn1,)    81920     81920        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
52          layer2_1_conv2                       (layer2_1_relu,)    81920     81920   147456         0         0         0    call_module           layer2.1.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]                1           3211200
53            layer2_1_bn2                      (layer2_1_conv2,)    81920     81920      256         0         0         0    call_module             layer2.1.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
54         layer2_1_relu_1                        (layer2_1_bn2,)    81920     81920        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
55          layer2_1_conv3                     (layer2_1_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.1.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]                1           3211200
56            layer2_1_bn3                      (layer2_1_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.1.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]                1           3211200
57                   add_4        (layer2_1_bn3, layer2_0_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]                1           3211200
58         layer2_1_relu_2                               (add_4,)   327680    327680        0         0         0         0    call_module            layer2.1.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]                1           3211200
59          layer2_2_conv1                     (layer2_1_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.2.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]                1           3211200
60            layer2_2_bn1                      (layer2_2_conv1,)    81920     81920      256         0         0         0    call_module             layer2.2.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
61           layer2_2_relu                        (layer2_2_bn1,)    81920     81920        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
62          layer2_2_conv2                       (layer2_2_relu,)    81920     81920   147456         0         0         0    call_module           layer2.2.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]                1           3211200
63            layer2_2_bn2                      (layer2_2_conv2,)    81920     81920      256         0         0         0    call_module             layer2.2.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
64         layer2_2_relu_1                        (layer2_2_bn2,)    81920     81920        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
65          layer2_2_conv3                     (layer2_2_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.2.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]                1           3211200
66            layer2_2_bn3                      (layer2_2_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.2.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]                1           3211200
67                   add_5        (layer2_2_bn3, layer2_1_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]                1           3211200
68         layer2_2_relu_2                               (add_5,)   327680    327680        0         0         0         0    call_module            layer2.2.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]                1           3211200
69          layer2_3_conv1                     (layer2_2_relu_2,)   327680     81920    65536         0         0         0    call_module           layer2.3.conv1       Conv2d    [10, 512, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 512, 1, 1)}     {}        [4]                1           3211200
70            layer2_3_bn1                      (layer2_3_conv1,)    81920     81920      256         0         0         0    call_module             layer2.3.bn1  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
71           layer2_3_relu                        (layer2_3_bn1,)    81920     81920        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
72          layer2_3_conv2                       (layer2_3_relu,)    81920     81920   147456         0         0         0    call_module           layer2.3.conv2       Conv2d    [10, 128, 8, 8]    [10, 128, 8, 8]           {'weight': (128, 128, 3, 3)}     {}        [4]                1           3211200
73            layer2_3_bn2                      (layer2_3_conv2,)    81920     81920      256         0         0         0    call_module             layer2.3.bn2  BatchNorm2d    [10, 128, 8, 8]    [10, 128, 8, 8]     {'weight': (128,), 'bias': (128,)}     {}        [4]                1           3211200
74         layer2_3_relu_1                        (layer2_3_bn2,)    81920     81920        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 128, 8, 8]    [10, 128, 8, 8]                                     {}     {}        [4]                1           3211200
75          layer2_3_conv3                     (layer2_3_relu_1,)    81920    327680    65536         0         0         0    call_module           layer2.3.conv3       Conv2d    [10, 128, 8, 8]    [10, 512, 8, 8]           {'weight': (512, 128, 1, 1)}     {}        [4]                1           3211200
76            layer2_3_bn3                      (layer2_3_conv3,)   327680    327680     1024         0         0         0    call_module             layer2.3.bn3  BatchNorm2d    [10, 512, 8, 8]    [10, 512, 8, 8]     {'weight': (512,), 'bias': (512,)}     {}        [4]                1           3211200
77                   add_6        (layer2_3_bn3, layer2_2_relu_2)   327680    327680        0         0         0         0  call_function  <built-in function add>         None    [10, 512, 8, 8]    [10, 512, 8, 8]                                      0     {}        [4]                1           3211200
78         layer2_3_relu_2                               (add_6,)   327680    327680        0         0         0         0    call_module            layer2.3.relu         ReLU    [10, 512, 8, 8]    [10, 512, 8, 8]                                     {}     {}        [4]                1           3211200
79          layer3_0_conv1                     (layer2_3_relu_2,)   327680     40960   131072         0         0         0    call_module           layer3.0.conv1       Conv2d    [10, 512, 8, 8]    [10, 256, 4, 4]           {'weight': (256, 512, 1, 1)}     {}        [4]                1           3211200
80            layer3_0_bn1                      (layer3_0_conv1,)    40960     40960      512         0         0         0    call_module             layer3.0.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
81           layer3_0_relu                        (layer3_0_bn1,)    40960     40960        0         0         0         0    call_module            layer3.0.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                1           3211200
82          layer3_0_conv2                       (layer3_0_relu,)    40960     40960   589824         0         0         0    call_module           layer3.0.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                1           3211200
83            layer3_0_bn2                      (layer3_0_conv2,)    40960     40960      512         0         0         0    call_module             layer3.0.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
84         layer3_0_relu_1                        (layer3_0_bn2,)    40960     40960        0         0         0         0    call_module            layer3.0.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                1           3211200
85          layer3_0_conv3                     (layer3_0_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.0.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                1           3211200
86            layer3_0_bn3                      (layer3_0_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.0.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                1           3211200
87   layer3_0_downsample_0                     (layer2_3_relu_2,)   327680    163840   524288         0         0         0    call_module    layer3.0.downsample.0       Conv2d    [10, 512, 8, 8]   [10, 1024, 4, 4]          {'weight': (1024, 512, 1, 1)}     {}        [4]                1           3211200
88   layer3_0_downsample_1               (layer3_0_downsample_0,)   163840    163840     2048         0         0         0    call_module    layer3.0.downsample.1  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                1           3211200
89                   add_7  (layer3_0_bn3, layer3_0_downsample_1)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                1           3211200
90         layer3_0_relu_2                               (add_7,)   163840    163840        0         0         0         0    call_module            layer3.0.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                1           3211200
91          layer3_1_conv1                     (layer3_0_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.1.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]                1           3211200
92            layer3_1_bn1                      (layer3_1_conv1,)    40960     40960      512         0         0         0    call_module             layer3.1.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                1           3211200
93           layer3_1_relu                        (layer3_1_bn1,)    40960     40960        0         0         0         0    call_module            layer3.1.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                1           3211200
94          layer3_1_conv2                       (layer3_1_relu,)    40960     40960   589824         0         0         0    call_module           layer3.1.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                2           3351552
95            layer3_1_bn2                      (layer3_1_conv2,)    40960     40960      512         0         0         0    call_module             layer3.1.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
96         layer3_1_relu_1                        (layer3_1_bn2,)    40960     40960        0         0         0         0    call_module            layer3.1.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
97          layer3_1_conv3                     (layer3_1_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.1.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                2           3351552
98            layer3_1_bn3                      (layer3_1_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.1.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                2           3351552
99                   add_8        (layer3_1_bn3, layer3_0_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                2           3351552
100        layer3_1_relu_2                               (add_8,)   163840    163840        0         0         0         0    call_module            layer3.1.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                2           3351552
101         layer3_2_conv1                     (layer3_1_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.2.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]                2           3351552
102           layer3_2_bn1                      (layer3_2_conv1,)    40960     40960      512         0         0         0    call_module             layer3.2.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
103          layer3_2_relu                        (layer3_2_bn1,)    40960     40960        0         0         0         0    call_module            layer3.2.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
104         layer3_2_conv2                       (layer3_2_relu,)    40960     40960   589824         0         0         0    call_module           layer3.2.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                2           3351552
105           layer3_2_bn2                      (layer3_2_conv2,)    40960     40960      512         0         0         0    call_module             layer3.2.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
106        layer3_2_relu_1                        (layer3_2_bn2,)    40960     40960        0         0         0         0    call_module            layer3.2.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
107         layer3_2_conv3                     (layer3_2_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.2.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                2           3351552
108           layer3_2_bn3                      (layer3_2_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.2.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                2           3351552
109                  add_9        (layer3_2_bn3, layer3_1_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                2           3351552
110        layer3_2_relu_2                               (add_9,)   163840    163840        0         0         0         0    call_module            layer3.2.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                2           3351552
111         layer3_3_conv1                     (layer3_2_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.3.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]                2           3351552
112           layer3_3_bn1                      (layer3_3_conv1,)    40960     40960      512         0         0         0    call_module             layer3.3.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
113          layer3_3_relu                        (layer3_3_bn1,)    40960     40960        0         0         0         0    call_module            layer3.3.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
114         layer3_3_conv2                       (layer3_3_relu,)    40960     40960   589824         0         0         0    call_module           layer3.3.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                2           3351552
115           layer3_3_bn2                      (layer3_3_conv2,)    40960     40960      512         0         0         0    call_module             layer3.3.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
116        layer3_3_relu_1                        (layer3_3_bn2,)    40960     40960        0         0         0         0    call_module            layer3.3.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
117         layer3_3_conv3                     (layer3_3_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.3.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                2           3351552
118           layer3_3_bn3                      (layer3_3_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.3.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                2           3351552
119                 add_10        (layer3_3_bn3, layer3_2_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                2           3351552
120        layer3_3_relu_2                              (add_10,)   163840    163840        0         0         0         0    call_module            layer3.3.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                2           3351552
121         layer3_4_conv1                     (layer3_3_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.4.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]                2           3351552
122           layer3_4_bn1                      (layer3_4_conv1,)    40960     40960      512         0         0         0    call_module             layer3.4.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                2           3351552
123          layer3_4_relu                        (layer3_4_bn1,)    40960     40960        0         0         0         0    call_module            layer3.4.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                2           3351552
124         layer3_4_conv2                       (layer3_4_relu,)    40960     40960   589824         0         0         0    call_module           layer3.4.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                3           2497024
125           layer3_4_bn2                      (layer3_4_conv2,)    40960     40960      512         0         0         0    call_module             layer3.4.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                3           2497024
126        layer3_4_relu_1                        (layer3_4_bn2,)    40960     40960        0         0         0         0    call_module            layer3.4.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                3           2497024
127         layer3_4_conv3                     (layer3_4_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.4.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                3           2497024
128           layer3_4_bn3                      (layer3_4_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.4.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                3           2497024
129                 add_11        (layer3_4_bn3, layer3_3_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                3           2497024
130        layer3_4_relu_2                              (add_11,)   163840    163840        0         0         0         0    call_module            layer3.4.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                3           2497024
131         layer3_5_conv1                     (layer3_4_relu_2,)   163840     40960   262144         0         0         0    call_module           layer3.5.conv1       Conv2d   [10, 1024, 4, 4]    [10, 256, 4, 4]          {'weight': (256, 1024, 1, 1)}     {}        [4]                3           2497024
132           layer3_5_bn1                      (layer3_5_conv1,)    40960     40960      512         0         0         0    call_module             layer3.5.bn1  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                3           2497024
133          layer3_5_relu                        (layer3_5_bn1,)    40960     40960        0         0         0         0    call_module            layer3.5.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                3           2497024
134         layer3_5_conv2                       (layer3_5_relu,)    40960     40960   589824         0         0         0    call_module           layer3.5.conv2       Conv2d    [10, 256, 4, 4]    [10, 256, 4, 4]           {'weight': (256, 256, 3, 3)}     {}        [4]                3           2497024
135           layer3_5_bn2                      (layer3_5_conv2,)    40960     40960      512         0         0         0    call_module             layer3.5.bn2  BatchNorm2d    [10, 256, 4, 4]    [10, 256, 4, 4]     {'weight': (256,), 'bias': (256,)}     {}        [4]                3           2497024
136        layer3_5_relu_1                        (layer3_5_bn2,)    40960     40960        0         0         0         0    call_module            layer3.5.relu         ReLU    [10, 256, 4, 4]    [10, 256, 4, 4]                                     {}     {}        [4]                3           2497024
137         layer3_5_conv3                     (layer3_5_relu_1,)    40960    163840   262144         0         0         0    call_module           layer3.5.conv3       Conv2d    [10, 256, 4, 4]   [10, 1024, 4, 4]          {'weight': (1024, 256, 1, 1)}     {}        [4]                3           2497024
138           layer3_5_bn3                      (layer3_5_conv3,)   163840    163840     2048         0         0         0    call_module             layer3.5.bn3  BatchNorm2d   [10, 1024, 4, 4]   [10, 1024, 4, 4]   {'weight': (1024,), 'bias': (1024,)}     {}        [4]                3           2497024
139                 add_12        (layer3_5_bn3, layer3_4_relu_2)   163840    163840        0         0         0         0  call_function  <built-in function add>         None   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                      0     {}        [4]                3           2497024
140        layer3_5_relu_2                              (add_12,)   163840    163840        0         0         0         0    call_module            layer3.5.relu         ReLU   [10, 1024, 4, 4]   [10, 1024, 4, 4]                                     {}     {}        [4]                3           2497024
141         layer4_0_conv1                     (layer3_5_relu_2,)   163840     20480   524288         0         0         0    call_module           layer4.0.conv1       Conv2d   [10, 1024, 4, 4]    [10, 512, 2, 2]          {'weight': (512, 1024, 1, 1)}     {}        [4]                3           2497024
142           layer4_0_bn1                      (layer4_0_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.0.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                3           2497024
143          layer4_0_relu                        (layer4_0_bn1,)    20480     20480        0         0         0         0    call_module            layer4.0.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                3           2497024
144         layer4_0_conv2                       (layer4_0_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.0.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]                4           3412992
145           layer4_0_bn2                      (layer4_0_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.0.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                4           3412992
146        layer4_0_relu_1                        (layer4_0_bn2,)    20480     20480        0         0         0         0    call_module            layer4.0.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                4           3412992
147         layer4_0_conv3                     (layer4_0_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.0.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]                4           3412992
148           layer4_0_bn3                      (layer4_0_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.0.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]                4           3412992
149  layer4_0_downsample_0                     (layer3_5_relu_2,)   163840     81920  2097152         0         0         0    call_module    layer4.0.downsample.0       Conv2d   [10, 1024, 4, 4]   [10, 2048, 2, 2]         {'weight': (2048, 1024, 1, 1)}     {}        [4]                5           3150848
150  layer4_0_downsample_1               (layer4_0_downsample_0,)    81920     81920     4096         0         0         0    call_module    layer4.0.downsample.1  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]                5           3150848
151                 add_13  (layer4_0_bn3, layer4_0_downsample_1)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]                5           3150848
152        layer4_0_relu_2                              (add_13,)    81920     81920        0         0         0         0    call_module            layer4.0.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]                5           3150848
153         layer4_1_conv1                     (layer4_0_relu_2,)    81920     20480  1048576         0         0         0    call_module           layer4.1.conv1       Conv2d   [10, 2048, 2, 2]    [10, 512, 2, 2]          {'weight': (512, 2048, 1, 1)}     {}        [4]                5           3150848
154           layer4_1_bn1                      (layer4_1_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.1.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                5           3150848
155          layer4_1_relu                        (layer4_1_bn1,)    20480     20480        0         0         0         0    call_module            layer4.1.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                5           3150848
156         layer4_1_conv2                       (layer4_1_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.1.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]                6           3412992
157           layer4_1_bn2                      (layer4_1_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.1.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                6           3412992
158        layer4_1_relu_1                        (layer4_1_bn2,)    20480     20480        0         0         0         0    call_module            layer4.1.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                6           3412992
159         layer4_1_conv3                     (layer4_1_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.1.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]                6           3412992
160           layer4_1_bn3                      (layer4_1_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.1.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]                6           3412992
161                 add_14        (layer4_1_bn3, layer4_0_relu_2)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]                6           3412992
162        layer4_1_relu_2                              (add_14,)    81920     81920        0         0         0         0    call_module            layer4.1.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]                6           3412992
163         layer4_2_conv1                     (layer4_1_relu_2,)    81920     20480  1048576         0         0         0    call_module           layer4.2.conv1       Conv2d   [10, 2048, 2, 2]    [10, 512, 2, 2]          {'weight': (512, 2048, 1, 1)}     {}        [4]                7           3409920
164           layer4_2_bn1                      (layer4_2_conv1,)    20480     20480     1024         0         0         0    call_module             layer4.2.bn1  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                7           3409920
165          layer4_2_relu                        (layer4_2_bn1,)    20480     20480        0         0         0         0    call_module            layer4.2.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                7           3409920
166         layer4_2_conv2                       (layer4_2_relu,)    20480     20480  2359296         0         0         0    call_module           layer4.2.conv2       Conv2d    [10, 512, 2, 2]    [10, 512, 2, 2]           {'weight': (512, 512, 3, 3)}     {}        [4]                7           3409920
167           layer4_2_bn2                      (layer4_2_conv2,)    20480     20480     1024         0         0         0    call_module             layer4.2.bn2  BatchNorm2d    [10, 512, 2, 2]    [10, 512, 2, 2]     {'weight': (512,), 'bias': (512,)}     {}        [4]                7           3409920
168        layer4_2_relu_1                        (layer4_2_bn2,)    20480     20480        0         0         0         0    call_module            layer4.2.relu         ReLU    [10, 512, 2, 2]    [10, 512, 2, 2]                                     {}     {}        [4]                7           3409920
169         layer4_2_conv3                     (layer4_2_relu_1,)    20480     81920  1048576         0         0         0    call_module           layer4.2.conv3       Conv2d    [10, 512, 2, 2]   [10, 2048, 2, 2]          {'weight': (2048, 512, 1, 1)}     {}        [4]                8           1073162
170           layer4_2_bn3                      (layer4_2_conv3,)    81920     81920     4096         0         0         0    call_module             layer4.2.bn3  BatchNorm2d   [10, 2048, 2, 2]   [10, 2048, 2, 2]   {'weight': (2048,), 'bias': (2048,)}     {}        [4]                8           1073162
171                 add_15        (layer4_2_bn3, layer4_1_relu_2)    81920     81920        0         0         0         0  call_function  <built-in function add>         None   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                      0     {}        [4]                8           1073162
172        layer4_2_relu_2                              (add_15,)    81920     81920        0         0         0         0    call_module            layer4.2.relu         ReLU   [10, 2048, 2, 2]   [10, 2048, 2, 2]                                     {}     {}        [4]                8           1073162
173                avgpool                     (layer4_2_relu_2,)    81920     20480        0         0         0         0    call_module                  avgpool    AvgPool2d   [10, 2048, 2, 2]   [10, 2048, 1, 1]                                     {}     {}        [4]                8           1073162
174                   size                           (avgpool, 0)    20480     20480        0         0         0         0    call_method                     size         None   [10, 2048, 1, 1]   [10, 2048, 1, 1]                                      0     {}        [4]                8           1073162
175                   view                    (avgpool, size, -1)    20480     20480        0         0         0         0    call_method                     view         None   [10, 2048, 1, 1]   [10, 2048, 1, 1]                                      0     {}        [4]                8           1073162
176                     fc                                (view,)    20480       100    20490         0         0         0    call_module                       fc       Linear         [10, 2048]           [10, 10]  {'weight': (10, 2048), 'bias': (10,)}     {}        [4]                8           1073162
177                 output                                  (fc,)      100       100        0         0         0         0         output                   output         None           [10, 10]           [10, 10]                                      0     {}        [4]                8           1073162
